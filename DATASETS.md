
# Datasets


Tried datasets: 
```
# english short form
hf-audio/esb-datasets-test-only-sorted ami test
hf-audio/esb-datasets-test-only-sorted common_voice test
hf-audio/esb-datasets-test-only-sorted earnings22 test
hf-audio/esb-datasets-test-only-sorted gigaspeech test
hf-audio/esb-datasets-test-only-sorted librispeech test.clean
hf-audio/esb-datasets-test-only-sorted librispeech test.other
hf-audio/esb-datasets-test-only-sorted spgispeech test
hf-audio/esb-datasets-test-only-sorted tedlium test
hf-audio/esb-datasets-test-only-sorted voxpopuli test

TwinkStart/peoples_speech default test
TwinkStart/audio-MNIST default test
TwinkStart/librispeech default dev_clean
TwinkStart/librispeech default dev_other
TwinkStart/librispeech default test_clean
TwinkStart/librispeech default test_other
TwinkStart/tedlium default test
TwinkStart/tedlium release1 test
TwinkStart/tedlium release2 test
TwinkStart/tedlium release3 test

adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-en default test

TwinkStart/llama-questions default test
TwinkStart/speech-chatbot-alpaca-eval default test
TwinkStart/speech-web-questions default test
TwinkStart/speech-triavia-qa default test
TwinkStart/air-chat default test



TwinkStart/AISHELL-1 default test
TwinkStart/kespeech default test
TwinkStart/WenetSpeech default test_meeting
TwinkStart/WenetSpeech default test_net

TwinkStart/speech-CMMLU default train
TwinkStart/speech-HSK default hsk1
TwinkStart/speech-HSK default hsk2
TwinkStart/speech-HSK default hsk3
TwinkStart/speech-HSK default hsk4
TwinkStart/speech-HSK default hsk5
TwinkStart/speech-HSK default hsk6

TwinkStart/CommonVoice_15 default zh

JacobLinCool/common_voice_19_0_zh-TW default validated_without_test
JacobLinCool/common_voice_19_0_zh-TW default test

adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-zhtw default test

adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-hokkien default test
adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-hakka default test

TwinkStart/CommonVoice_15 default yue


nithinraok/asr-leaderboard-datasets fleurs_bg test
nithinraok/asr-leaderboard-datasets fleurs_cs test
nithinraok/asr-leaderboard-datasets fleurs_da test
nithinraok/asr-leaderboard-datasets fleurs_de test
nithinraok/asr-leaderboard-datasets fleurs_el test
nithinraok/asr-leaderboard-datasets fleurs_en test
nithinraok/asr-leaderboard-datasets fleurs_es test
nithinraok/asr-leaderboard-datasets fleurs_et test
nithinraok/asr-leaderboard-datasets fleurs_fi test
nithinraok/asr-leaderboard-datasets fleurs_fr test
nithinraok/asr-leaderboard-datasets fleurs_hr test
nithinraok/asr-leaderboard-datasets fleurs_hu test
nithinraok/asr-leaderboard-datasets fleurs_it test
nithinraok/asr-leaderboard-datasets fleurs_lt test
nithinraok/asr-leaderboard-datasets fleurs_lv test
nithinraok/asr-leaderboard-datasets fleurs_mt test
nithinraok/asr-leaderboard-datasets fleurs_nl test
nithinraok/asr-leaderboard-datasets fleurs_pl test
nithinraok/asr-leaderboard-datasets fleurs_pt test
nithinraok/asr-leaderboard-datasets fleurs_ro test
nithinraok/asr-leaderboard-datasets fleurs_ru test
nithinraok/asr-leaderboard-datasets fleurs_sk test
nithinraok/asr-leaderboard-datasets fleurs_sl test
nithinraok/asr-leaderboard-datasets fleurs_sv test
nithinraok/asr-leaderboard-datasets fleurs_uk test

nithinraok/asr-leaderboard-datasets mcv_de test
nithinraok/asr-leaderboard-datasets mcv_en test
nithinraok/asr-leaderboard-datasets mcv_es test
nithinraok/asr-leaderboard-datasets mcv_et test
nithinraok/asr-leaderboard-datasets mcv_fr test
nithinraok/asr-leaderboard-datasets mcv_it test
nithinraok/asr-leaderboard-datasets mcv_lv test
nithinraok/asr-leaderboard-datasets mcv_nl test
nithinraok/asr-leaderboard-datasets mcv_pt test
nithinraok/asr-leaderboard-datasets mcv_ru test
nithinraok/asr-leaderboard-datasets mcv_sl test
nithinraok/asr-leaderboard-datasets mcv_sv test
nithinraok/asr-leaderboard-datasets mcv_uk test

nithinraok/asr-leaderboard-datasets mls_es test
nithinraok/asr-leaderboard-datasets mls_fr test
nithinraok/asr-leaderboard-datasets mls_it test
nithinraok/asr-leaderboard-datasets mls_nl test
nithinraok/asr-leaderboard-datasets mls_pl test
nithinraok/asr-leaderboard-datasets mls_pt test

TwinkStart/facebook_multilingual_librispeech default mls_dutch
TwinkStart/facebook_multilingual_librispeech default mls_french
TwinkStart/facebook_multilingual_librispeech default mls_german
TwinkStart/facebook_multilingual_librispeech default mls_italian
TwinkStart/facebook_multilingual_librispeech default mls_polish
TwinkStart/facebook_multilingual_librispeech default mls_portuguese
TwinkStart/facebook_multilingual_librispeech default mls_spanish

TwinkStart/CommonVoice_15 default en
TwinkStart/CommonVoice_15 default fr



espnet/floras monolingual dev
espnet/floras monolingual test
espnet/floras multilingual dev
espnet/floras multilingual test

hf-audio/asr-leaderboard-longform earnings21 test
hf-audio/asr-leaderboard-longform earnings22 test
hf-audio/asr-leaderboard-longform tedlium test

distil-whisper/meanwhile default test
distil-whisper/rev16 whisper_subset test
distil_whisper/tedlium-long-form default validation


# for training
adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-en default train

adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-zhtw default train
adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-hokkien default train
adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-hakka default train

espnet/floras monolingual train

OmniAICreator/ASMR-Archive-Processed default train

# not suitable for ASR
TwinkStart/MMAU default v05.15.25
distil-whisper/rev16 full test

# needs additional preprocessing, also not compatible with streaming
speechcolab/gigaspeech2 default train

```


For exploring datasets

```
from datasets import load_dataset, get_dataset_split_names, get_dataset_config_names
ds_repos_en_short = ['hf-audio/esb-datasets-test-only-sorted', 'TwinkStart/peoples_speech', 'TwinkStart/audio-MNIST', 'TwinkStart/librispeech', 'TwinkStart/tedlium', 'adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-en']
ds_repos_zh_short = ['TwinkStart/AISHELL-1', 'TwinkStart/kespeech', 'TwinkStart/WenetSpeech', 'JacobLinCool/common_voice_19_0_zh-TW', 'adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-zhtw', 'adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-hokkien', 'adi-gov-tw/Taiwan-Tongues-ASR-CE-dataset-hakka',]
ds_repos_nlp = ['TwinkStart/llama-questions', 'TwinkStart/speech-chatbot-alpaca-eval', 'TwinkStart/speech-web-questions', 'TwinkStart/speech-triavia-qa', 'TwinkStart/air-chat', 'TwinkStart/speech-CMMLU', 'TwinkStart/speech-HSK']
ds_repos_ml = ['nithinraok/asr-leaderboard-datasets', 'TwinkStart/CommonVoice_15', 'TwinkStart/facebook_multilingual_librispeech', 'OmniAICreator/ASMR-Archive-Processed']
ds_repos_ml_long = ['espnet/floras']
ds_repos_long = ['hf-audio/asr-leaderboard-longform', 'distil-whisper/meanwhile', 'distil-whisper/rev16', 'distil_whisper/tedlium-long-form]
ds_repos_train = ['fixie-ai/common_voice_17_0']
ds_repos = ds_repos_en_short + ds_repos_zh_short + ds_repos_nlp + ds_repos_ml + ds_repos_ml_long + ds_repos_long


combs = []
for ds in ds_repos:
    cfgs = get_dataset_config_names(ds)
    for cfg in cfgs:
        splits = get_dataset_split_names(ds, cfg)
        for split in splits:
            print(ds, cfg, split)
            combs.append({'ds': ds, 'cfg': cfg, 'split': split})

for i in combs:
    print(i['ds'], i['cfg'], i['split'])
    try:
        dataset = load_dataset(i['ds'], i['cfg'], split=i['split'], streaming=True, token=True)
        print(next(iter(dataset)))
    except:
        print('cannot load data')
```


## Datasets with issues

Depending on pytorch / datasets version the datasets ['audio'] returns a datasets.features._torchcodec.AudioDecoder object or a decoded numpy object with 'array' field.
'array' field is necessary for later part of pipeline. most also include 'sampling_rate'
Some like the TwinkStart/ come as mp3 files so they need newer libraries to decode.

```
# datasets with issues
# pip install datasets<4.0.0 
# 'wenet-e2e/wenetspeech', 'fsicoli/common_voice_15_0', 'fsicoli/common_voice_22_0',
# issue parsing json content (different types)
# 'ASLP-lab/WenetSpeech-Yue', 
# column names dont match
# 'ASLP-lab/WSYue-ASR-eval'
# no audio (need to extract from some videos but no code for that) or transcription data 
# 'ASLP-lab/WSC-Train', 'ASLP-lab/WSC-Eval',
# missing transcriptions or audio
# 'AISHELL/AISHELL-1', 'AISHELL/AISHELL-3', 'AISHELL/AISHELL-4', 

# not suitable for ASR
# 'TwinkStart/MMAU', 
# TwinkStart/MMAU default v05.15.25

# needs additional preprocessing, also not compatible with streaming
# speechcolab/gigaspeech2 default train
```

